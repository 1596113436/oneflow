#include "oneflow/core/framework/op_generated.h"

namespace oneflow {

/* static */ Maybe<void> TopKOp::InferLogicalTensorDesc(user_op::InferContext *ctx) {
      const Shape& in_shape = ctx->InputShape("in", 0);
      Shape* out_shape = ctx->OutputShape("out", 0);
      *out_shape = in_shape;
      out_shape->Set(
          in_shape.NumAxes() - 1,
          std::min(ctx->Attr<int32_t>("k"), static_cast<int32_t>(in_shape.dim_vec().back())));
      return Maybe<void>::Ok();
    }

/*static*/ Maybe<void> TopKOp::InferPhysicalTensorDesc(user_op::InferContext* ctx) {return InferLogicalTensorDesc(ctx);}

/* static */ Maybe<void> TopKOp::GetSbp(user_op::SbpContext *ctx) {
      // The current implementation can only do top_k in the last dimension and should use Broadcast
      // (by default) instead of Split for that dimension
      const user_op::TensorDesc& in_tensor = ctx->LogicalTensorDesc4InputArgNameAndIndex("in", 0);
      FOR_RANGE(int64_t, i, 0, in_tensor.shape().NumAxes() - 1) {
        ctx->NewBuilder().Split(ctx->inputs(), i).Split(ctx->outputs(), i).Build();
      }
      return Maybe<void>::Ok();
    }

/* static */ Maybe<void> TopKOp::InferDataType(user_op::InferContext *ctx) {
      *ctx->OutputDType("out", 0) = DataType::kInt64;
      return Maybe<void>::Ok();
    }

